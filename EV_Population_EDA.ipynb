{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Electric Vehicle Population - Exploratory Data Analysis (EDA)\n",
    "\n",
    "This notebook provides a comprehensive framework for performing EDA on Electric Vehicle Population datasets.\n",
    "\n",
    "**Tools Used:** Python (Pandas, Matplotlib, Seaborn, NumPy)\n",
    "\n",
    "**Author:** HexSoftwares\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries\n",
    "\n",
    "First, let's import all necessary libraries for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"✓ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load the Dataset\n",
    "\n",
    "**PROMPT:** Load your Electric Vehicle Population dataset here.\n",
    "\n",
    "Replace `'your_data_path.csv'` with the actual path to your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data_path = 'electric_vehicle_population.csv'  # Update this path\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(data_path)\n",
    "    print(f\"✓ Data loaded successfully!\")\n",
    "    print(f\"  Shape: {df.shape[0]:,} rows × {df.shape[1]} columns\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"✗ Error: File not found at {data_path}\")\n",
    "    print(\"\\nPROMPT: Please update the 'data_path' variable with the correct file path.\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error loading data: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initial Data Exploration\n",
    "\n",
    "Let's get a first look at our dataset structure and contents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Display First Few Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first 10 rows\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Display Last Few Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display last 10 rows\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Dataset Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataset info\n",
    "print(\"Dataset Information:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total rows: {df.shape[0]:,}\")\n",
    "print(f\"Total columns: {df.shape[1]}\")\n",
    "print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "print(\"\\nColumn Details:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Identify Column Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numeric and categorical columns\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "print(f\"Numeric Columns ({len(numeric_cols)}):\")\n",
    "print(numeric_cols)\n",
    "print(f\"\\nCategorical Columns ({len(categorical_cols)}):\")\n",
    "print(categorical_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Statistical Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary for numeric columns\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary for categorical columns\n",
    "if len(categorical_cols) > 0:\n",
    "    df[categorical_cols].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Missing Values Analysis\n",
    "\n",
    "**PROMPT:** Identify and analyze missing values in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Check Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create missing values summary\n",
    "missing_df = pd.DataFrame({\n",
    "    'Column': df.columns,\n",
    "    'Missing_Count': df.isnull().sum(),\n",
    "    'Missing_Percentage': (df.isnull().sum() / len(df) * 100).round(2),\n",
    "    'Data_Type': df.dtypes\n",
    "})\n",
    "\n",
    "missing_df = missing_df[missing_df['Missing_Count'] > 0].sort_values(\n",
    "    'Missing_Percentage', ascending=False\n",
    ").reset_index(drop=True)\n",
    "\n",
    "if len(missing_df) == 0:\n",
    "    print(\"✓ No missing values found in the dataset!\")\n",
    "else:\n",
    "    print(f\"⚠ Found missing values in {len(missing_df)} columns:\\n\")\n",
    "    display(missing_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Visualize Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize missing values\n",
    "if len(missing_df) > 0:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(missing_df['Column'], missing_df['Missing_Percentage'], color='coral')\n",
    "    plt.xlabel('Missing Percentage (%)', fontsize=12)\n",
    "    plt.ylabel('Columns', fontsize=12)\n",
    "    plt.title('Missing Values by Column', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Handle Missing Values\n",
    "\n",
    "**PROMPT:** Choose a strategy to handle missing values:\n",
    "- Fill numeric columns with median\n",
    "- Fill categorical columns with mode\n",
    "- Drop rows with missing values\n",
    "- Custom strategy per column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values - Auto strategy\n",
    "# Fill numeric with median, categorical with mode\n",
    "\n",
    "for col in numeric_cols:\n",
    "    if df[col].isnull().sum() > 0:\n",
    "        df[col].fillna(df[col].median(), inplace=True)\n",
    "        print(f\"✓ Filled '{col}' with median\")\n",
    "\n",
    "for col in categorical_cols:\n",
    "    if df[col].isnull().sum() > 0:\n",
    "        df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "        print(f\"✓ Filled '{col}' with mode\")\n",
    "\n",
    "print(f\"\\n✓ Missing values handled. Remaining: {df.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Quality Checks\n",
    "\n",
    "### 5.1 Check for Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate rows\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"Duplicate rows: {duplicates:,} ({duplicates/len(df)*100:.2f}%)\")\n",
    "\n",
    "if duplicates > 0:\n",
    "    print(\"\\nPROMPT: Consider removing duplicates using: df.drop_duplicates(inplace=True)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Unique Values Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique values per column\n",
    "unique_df = pd.DataFrame({\n",
    "    'Column': df.columns,\n",
    "    'Unique_Count': [df[col].nunique() for col in df.columns],\n",
    "    'Unique_Percentage': [(df[col].nunique() / len(df)) * 100 for col in df.columns]\n",
    "})\n",
    "\n",
    "unique_df = unique_df.sort_values('Unique_Count', ascending=False).reset_index(drop=True)\n",
    "unique_df['Unique_Percentage'] = unique_df['Unique_Percentage'].round(2)\n",
    "\n",
    "display(unique_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Statistical Analysis\n",
    "\n",
    "### 6.1 Distribution Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze distribution metrics for numeric columns\n",
    "print(\"Distribution Metrics (Numeric Columns):\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for col in numeric_cols:\n",
    "    skew = df[col].skew()\n",
    "    kurt = df[col].kurtosis()\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  • Mean: {df[col].mean():.2f}\")\n",
    "    print(f\"  • Median: {df[col].median():.2f}\")\n",
    "    print(f\"  • Std Dev: {df[col].std():.2f}\")\n",
    "    print(f\"  • Min: {df[col].min():.2f}\")\n",
    "    print(f\"  • Max: {df[col].max():.2f}\")\n",
    "    print(f\"  • Skewness: {skew:.2f} {'(Right-skewed)' if skew > 0 else '(Left-skewed)' if skew < 0 else '(Symmetric)'}\")\n",
    "    print(f\"  • Kurtosis: {kurt:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix\n",
    "if len(numeric_cols) > 1:\n",
    "    corr_matrix = df[numeric_cols].corr()\n",
    "    print(\"Correlation Matrix:\")\n",
    "    display(corr_matrix.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Outlier Detection\n",
    "\n",
    "**PROMPT:** Detect outliers using the IQR (Interquartile Range) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect outliers using IQR method\n",
    "print(\"Outlier Detection (IQR Method):\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "outliers_dict = {}\n",
    "\n",
    "for col in numeric_cols:\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)][col]\n",
    "    \n",
    "    if len(outliers) > 0:\n",
    "        outliers_dict[col] = len(outliers)\n",
    "        print(f\"⚠ '{col}': {len(outliers):,} outliers ({len(outliers)/len(df)*100:.2f}%)\")\n",
    "\n",
    "if len(outliers_dict) == 0:\n",
    "    print(\"✓ No significant outliers detected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Data Visualizations\n",
    "\n",
    "### 8.1 Distribution Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create distribution plots for numeric columns\n",
    "if len(numeric_cols) > 0:\n",
    "    n_cols = len(numeric_cols)\n",
    "    n_rows = (n_cols + 2) // 3\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, 3, figsize=(15, 5*n_rows))\n",
    "    axes = axes.flatten() if n_cols > 1 else [axes]\n",
    "    \n",
    "    for idx, col in enumerate(numeric_cols):\n",
    "        if idx < len(axes):\n",
    "            axes[idx].hist(df[col].dropna(), bins=30, edgecolor='black', alpha=0.7, color='skyblue')\n",
    "            axes[idx].set_title(f'Distribution of {col}', fontweight='bold')\n",
    "            axes[idx].set_xlabel(col)\n",
    "            axes[idx].set_ylabel('Frequency')\n",
    "            axes[idx].grid(alpha=0.3)\n",
    "    \n",
    "    # Hide extra subplots\n",
    "    for idx in range(n_cols, len(axes)):\n",
    "        axes[idx].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Correlation Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create correlation heatmap\n",
    "if len(numeric_cols) > 1:\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    corr_matrix = df[numeric_cols].corr()\n",
    "    \n",
    "    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0,\n",
    "                square=True, linewidths=1, fmt='.2f', cbar_kws={\"shrink\": 0.8})\n",
    "    plt.title('Correlation Matrix - Electric Vehicle Population', fontsize=16, fontweight='bold', pad=20)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 Box Plots (Outlier Visualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create box plots for outlier detection\n",
    "if len(numeric_cols) > 0:\n",
    "    n_cols = len(numeric_cols)\n",
    "    n_rows = (n_cols + 2) // 3\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, 3, figsize=(15, 5*n_rows))\n",
    "    axes = axes.flatten() if n_cols > 1 else [axes]\n",
    "    \n",
    "    for idx, col in enumerate(numeric_cols):\n",
    "        if idx < len(axes):\n",
    "            axes[idx].boxplot(df[col].dropna(), patch_artist=True,\n",
    "                            boxprops=dict(facecolor='lightblue'))\n",
    "            axes[idx].set_title(f'Box Plot: {col}', fontweight='bold')\n",
    "            axes[idx].set_ylabel(col)\n",
    "            axes[idx].grid(alpha=0.3)\n",
    "    \n",
    "    # Hide extra subplots\n",
    "    for idx in range(n_cols, len(axes)):\n",
    "        axes[idx].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4 Categorical Variables Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize categorical variables\n",
    "if len(categorical_cols) > 0:\n",
    "    top_n = 10\n",
    "    n_cols = len(categorical_cols)\n",
    "    n_rows = (n_cols + 1) // 2\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, 2, figsize=(15, 5*n_rows))\n",
    "    axes = axes.flatten() if n_cols > 1 else [axes]\n",
    "    \n",
    "    for idx, col in enumerate(categorical_cols):\n",
    "        if idx < len(axes):\n",
    "            value_counts = df[col].value_counts().head(top_n)\n",
    "            axes[idx].barh(range(len(value_counts)), value_counts.values, color='steelblue')\n",
    "            axes[idx].set_yticks(range(len(value_counts)))\n",
    "            axes[idx].set_yticklabels(value_counts.index)\n",
    "            axes[idx].set_title(f'Top {top_n} Categories: {col}', fontweight='bold')\n",
    "            axes[idx].set_xlabel('Count')\n",
    "            axes[idx].invert_yaxis()\n",
    "            \n",
    "            # Add value labels\n",
    "            for i, v in enumerate(value_counts.values):\n",
    "                axes[idx].text(v, i, f' {v:,}', va='center')\n",
    "    \n",
    "    # Hide extra subplots\n",
    "    for idx in range(n_cols, len(axes)):\n",
    "        axes[idx].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Key Insights and Patterns\n",
    "\n",
    "**PROMPT:** Based on the analysis above, document key insights about the Electric Vehicle population:\n",
    "\n",
    "### Questions to Answer:\n",
    "\n",
    "1. **Distribution Patterns:**\n",
    "   - What is the distribution of electric vehicles by make and model?\n",
    "   - Which EV types are most common (BEV vs PHEV)?\n",
    "\n",
    "2. **Geographic Insights:**\n",
    "   - Which counties/cities have the highest EV adoption?\n",
    "   - Are there geographic clusters?\n",
    "\n",
    "3. **Temporal Trends:**\n",
    "   - How has EV adoption changed over the years?\n",
    "   - What is the distribution of model years?\n",
    "\n",
    "4. **Technical Specifications:**\n",
    "   - What is the average electric range?\n",
    "   - How does range vary by manufacturer?\n",
    "\n",
    "5. **Data Quality:**\n",
    "   - Which features have the most missing data?\n",
    "   - Are there any data quality issues to address?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Advanced Analysis (Optional)\n",
    "\n",
    "### 10.1 Time Series Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Analyze EV adoption over time (if Model Year column exists)\n",
    "# Uncomment and modify based on your dataset columns\n",
    "\n",
    "# if 'Model Year' in df.columns:\n",
    "#     yearly_counts = df['Model Year'].value_counts().sort_index()\n",
    "#     \n",
    "#     plt.figure(figsize=(14, 6))\n",
    "#     plt.plot(yearly_counts.index, yearly_counts.values, marker='o', linewidth=2, markersize=8)\n",
    "#     plt.xlabel('Model Year', fontsize=12)\n",
    "#     plt.ylabel('Number of Vehicles', fontsize=12)\n",
    "#     plt.title('Electric Vehicle Adoption Over Time', fontsize=14, fontweight='bold')\n",
    "#     plt.grid(alpha=0.3)\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2 Geographic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Top cities/counties with most EVs\n",
    "# Uncomment and modify based on your dataset columns\n",
    "\n",
    "# if 'County' in df.columns:\n",
    "#     top_counties = df['County'].value_counts().head(15)\n",
    "#     \n",
    "#     plt.figure(figsize=(12, 8))\n",
    "#     plt.barh(range(len(top_counties)), top_counties.values, color='green', alpha=0.7)\n",
    "#     plt.yticks(range(len(top_counties)), top_counties.index)\n",
    "#     plt.xlabel('Number of Electric Vehicles', fontsize=12)\n",
    "#     plt.title('Top 15 Counties by EV Population', fontsize=14, fontweight='bold')\n",
    "#     plt.gca().invert_yaxis()\n",
    "#     plt.grid(alpha=0.3, axis='x')\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3 Manufacturer Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Top EV manufacturers\n",
    "# Uncomment and modify based on your dataset columns\n",
    "\n",
    "# if 'Make' in df.columns:\n",
    "#     top_makes = df['Make'].value_counts().head(10)\n",
    "#     \n",
    "#     plt.figure(figsize=(12, 6))\n",
    "#     plt.bar(range(len(top_makes)), top_makes.values, color='steelblue', alpha=0.8)\n",
    "#     plt.xticks(range(len(top_makes)), top_makes.index, rotation=45, ha='right')\n",
    "#     plt.xlabel('Manufacturer', fontsize=12)\n",
    "#     plt.ylabel('Number of Vehicles', fontsize=12)\n",
    "#     plt.title('Top 10 EV Manufacturers', fontsize=14, fontweight='bold')\n",
    "#     plt.grid(alpha=0.3, axis='y')\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Export Results\n",
    "\n",
    "### 11.1 Save Cleaned Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned dataset\n",
    "df.to_csv('ev_population_cleaned.csv', index=False)\n",
    "print(\"✓ Cleaned dataset saved as 'ev_population_cleaned.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.2 Generate Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive summary report\n",
    "report = f\"\"\"\n",
    "Electric Vehicle Population - EDA Summary Report\n",
    "{'='*80}\n",
    "\n",
    "Dataset Overview:\n",
    "-----------------\n",
    "• Total Records: {df.shape[0]:,}\n",
    "• Total Features: {df.shape[1]}\n",
    "• Memory Usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\n",
    "• Numeric Columns: {len(numeric_cols)}\n",
    "• Categorical Columns: {len(categorical_cols)}\n",
    "\n",
    "Data Quality:\n",
    "-------------\n",
    "• Missing Values: {df.isnull().sum().sum():,} ({df.isnull().sum().sum() / (df.shape[0] * df.shape[1]) * 100:.2f}%)\n",
    "• Duplicate Rows: {df.duplicated().sum():,}\n",
    "\n",
    "Column Information:\n",
    "-------------------\n",
    "\"\"\"\n",
    "\n",
    "for col in df.columns:\n",
    "    report += f\"\\n{col}:\"\n",
    "    report += f\"\\n  Type: {df[col].dtype}\"\n",
    "    report += f\"\\n  Unique Values: {df[col].nunique():,}\"\n",
    "    if col in numeric_cols:\n",
    "        report += f\"\\n  Mean: {df[col].mean():.2f}\"\n",
    "        report += f\"\\n  Median: {df[col].median():.2f}\"\n",
    "        report += f\"\\n  Std: {df[col].std():.2f}\"\n",
    "    report += \"\\n\"\n",
    "\n",
    "print(report)\n",
    "\n",
    "# Save report to file\n",
    "with open('eda_summary_report.txt', 'w') as f:\n",
    "    f.write(report)\n",
    "print(\"\\n✓ Summary report saved as 'eda_summary_report.txt'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Conclusion\n",
    "\n",
    "**PROMPT:** Summarize your key findings here:\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "1. **Dataset Characteristics:**\n",
    "   - [Add your findings]\n",
    "\n",
    "2. **Data Quality Issues:**\n",
    "   - [Add your findings]\n",
    "\n",
    "3. **Distribution Patterns:**\n",
    "   - [Add your findings]\n",
    "\n",
    "4. **Correlations:**\n",
    "   - [Add your findings]\n",
    "\n",
    "5. **Actionable Insights:**\n",
    "   - [Add your recommendations]\n",
    "\n",
    "---\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. Further cleaning and preprocessing\n",
    "2. Feature engineering for modeling\n",
    "3. Predictive modeling (if applicable)\n",
    "4. Dashboard creation for stakeholders\n",
    "\n",
    "---\n",
    "\n",
    "**End of EDA Report**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
